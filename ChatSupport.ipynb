{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Vc9pe8Nde6WT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from transformers import AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hcz3O391e6WU"
      },
      "outputs": [],
      "source": [
        "# Initialize tokenizer for the model you want to use\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hIrCE49de6WV"
      },
      "outputs": [],
      "source": [
        "# Initialize text generation pipeline with the tokenizer and model\n",
        "text_generator = pipeline(\"text-generation\", model=\"gpt2\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wsC1nM7Ke6WV"
      },
      "outputs": [],
      "source": [
        "# List of paths to your text files\n",
        "text_files = [\n",
        "    \"Aadhar_Faq.txt\",\n",
        "    \"Amazon_sagemaker_Faq.txt\",\n",
        "    \"faq_results.txt\",\n",
        "    \"HDFC_Faq.txt\",\n",
        "    \"Sevenhillshospital_faq.txt\",\n",
        "    \"Tata_comm_faq.txt\",\n",
        "] \n",
        "# Add the documentation files here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0cylVMx4oocm"
      },
      "outputs": [],
      "source": [
        "# Process each text file\n",
        "combined_text = \"\"\n",
        "for file_path in text_files:\n",
        "    # Read the text from the file\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eMv74ybBoqja"
      },
      "outputs": [],
      "source": [
        "# Extract questions and answers from the dataset\n",
        "for item in data:\n",
        "        question = item.get(\"question\", \"\")\n",
        "        answer = item.get(\"answer\", \"\")\n",
        "        if question and answer:\n",
        "            combined_text += f\"Q: {question}\\nA: {answer}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8MSqBtAqh6cC"
      },
      "outputs": [],
      "source": [
        "# Create a prompt based on the combined text\n",
        "prompt = \"\" # Add your prompt here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N77itEDYe6WV",
        "outputId": "c3898111-09cb-47ec-c0cc-2eb263c6fbcd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "# Generate text based on the content of the file with max_new_tokens\n",
        "generated_text = text_generator(prompt, max_new_tokens=50, num_return_sequences=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G01J5pRYp711",
        "outputId": "ab70a876-18b8-48ad-991d-14d5fdb8ba75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'combined_text[:100]><font face=\"Liberation Sans\" color=\"#0000\">7%</font></font></ui>\\n\\nThis is where you come to the interesting part. For example, here\\'s the output of the current locale:\\n\\nhttp://en.wikipedia.org/wiki/Languages_in_Latin1?context=en\\n\\nIt is possible to create additional translators (both in English and in Latin1), so the final locale output is that:\\n\\nhttp://'}]\n"
          ]
        }
      ],
      "source": [
        "print(generated_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
